{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction\n",
    "\n",
    "- Bowen Li\n",
    "- 2017/06/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Dimensionality reduction** techniques translate high-dimensional data into lower dimensional data, and are building blocks we will need if we wish to visualize machine learning, and deep learning specifically.\n",
    "\n",
    "The following notebook are mainly revised from the insightful Colah (Research Scientist at Google Brain)'s [blog post](http://colah.github.io/posts/2014-10-Visualizing-MNIST/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Components Analysis (PCA)\n",
    "\n",
    "- Will find the best possible \"angle\" for us. \n",
    "- By this, we mean that PCA will find the angle that spreads out the points the most (captures the most variance possible).\n",
    "- Unfortunately, even looking at the data from the best angle, some data doesn’t line up nicely for us to look at. \n",
    "- It’s a non-trivial high-dimensional structure, and these sorts of linear projections just aren’t going to cut it.\n",
    "- For detailed introduction to PCA (and SVD), please refer to [my post](https://bowen0701.github.io/2016/10/05/ml-pca-svd)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we discuss some **optimization-based dimension reduction techniques.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional Scaling (or MDS)\n",
    "\n",
    "- If the distances between points in our visualization were the same as the distances between points in the original space. \n",
    "- If that was true, we’d be capturing the global geometry of the data.\n",
    "\n",
    "$$\n",
    "C = \\sum_{i \\neq j} (\\hat d^{i,j} − d_{i,j})^2\n",
    "$$\n",
    "\n",
    "- Solve d_{i,j} with random starting point and apply gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sammon’s Mapping\n",
    "\n",
    "- Consider different cost functions: cost functions emphasizing local structure as more important to maintain than global structure.\n",
    "\n",
    "$$\n",
    "C = \\sum_{i \\neq j} (\\hat d{i,j} − d_{i,j})^2 / \\hat d^{i,j}\n",
    "$$\n",
    "\n",
    "- Nevertheless, the difference between the very different data points, d(9, 3), is less than three times d(1, 1)!\n",
    "- Because there’s so many ways similar points can be slightly different, the average distance between similar points is quite high. \n",
    "- Conversely, as you get further away from a point, the amount of volume within that distance increases to an extremely high power, and so you are likely to run into different kinds of points. \n",
    "- The result is that, in pixel space, the difference in distances between ‘similar’ and ‘different’ points can be much less than we’d like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are graph-based visualization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Force-Directed Graph Drawing\n",
    "\n",
    "- Consider a nearest neighbor graph of MNIST. For example, consider a graph (V,E) where the nodes are MNIST data points, and each point is connected to the three points that are closest to it in the original space\n",
    "- Pretend that all points are repelling charged particles, and that the edges are springs.\n",
    "- Cost function:\n",
    "\n",
    "$$\n",
    "C = \\sum_{i \\neq j} 1/d_{i, j} + 1/2 \\sum_{(i, j) \\in E} (d_{i, j} - d_{i, j})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "- What t-SNE tries to optimize for is preserving the topology of the data. \n",
    "- For every point, it constructs a notion of which other points are its ‘neighbors,’ trying to make all points have the same number of neighbors. Then it tries to embed them so that those points all have the same number of neighbors.\n",
    "- In some ways, t-SNE is a lot like the graph based visualization. But instead of just having points be neighbors (if there’s an edge) or not neighbors (if there isn’t an edge), t-SNE has a continuous spectrum of having points be neighbors to different extents.\n",
    "- t-SNE is often very successful at revealing clusters and subclusters in data.\n",
    "- But it is prone to getting stuck in local minima.\n",
    "\n",
    "For details please see the future notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussions\n",
    "\n",
    "- There’s no way to map high-dimensional data into low dimensions and preserve all the structure. So, an approach must make trade-offs, sacrificing one property to preserve another. \n",
    "- PCA tries to **preserve linear structure.**\n",
    "- MDS tries to **preserve global geometry.**\n",
    "- t-SNE tries to **preserve topology**\n",
    "  * That is, neighborhood structure, which means local similarity of the data.\n",
    "  * Makes sure things are close to you are still close to you in low dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "- colah.github.io (2014). [Visualizing MNIST: An Exploration of Dimensionality Reduction](http://colah.github.io/posts/2014-10-Visualizing-MNIST/)\n",
    "- bowen0701.github.io (2016). [ML Notes: Principal Component Analysis & Singular Value Decomposition](https://bowen0701.github.io/2016/10/05/ml-pca-svd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
