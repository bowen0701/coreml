{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Implementation of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch imports.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# TensorFlow import.\n",
    "import tensorflow as tf\n",
    "\n",
    "# MXNet imports.\n",
    "# from mxnet import nd, autograd, init, gluon\n",
    "# from mxnet.gluon import data as gdata\n",
    "# from mxnet.gluon import nn\n",
    "# from mxnet.gluon import loss as gloss\n",
    "\n",
    "np.random.seed(71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    \"\"\"Numpy implementation of Linear Regression.\"\"\"\n",
    "    def __init__(self, batch_size=64, lr=0.01, n_epochs=1000):\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "    def get_data(self, X_train, y_train, shuffle=True):\n",
    "        \"\"\"Get dataset and information.\"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        # Get the numbers of examples and inputs.\n",
    "        self.n_examples, self.n_inputs = self.X_train.shape\n",
    "\n",
    "        if shuffle:\n",
    "            idx = list(range(self.n_examples))\n",
    "            random.shuffle(idx)\n",
    "            self.X_train = self.X_train[idx]\n",
    "            self.y_train = self.y_train[idx]\n",
    "\n",
    "    def _create_weights(self):\n",
    "        \"\"\"Create model weights and bias.\"\"\"\n",
    "        self.w = np.zeros(self.n_inputs).reshape(self.n_inputs, 1)\n",
    "        self.b = np.zeros(1).reshape(1, 1)\n",
    "\n",
    "    def _model(self, X):\n",
    "        \"\"\"Linear regression model.\"\"\"\n",
    "        return np.matmul(X, self.w) + self.b\n",
    "\n",
    "    def _loss(self, y, y_):\n",
    "        \"\"\"Squared error loss.\n",
    "\n",
    "        # squared_error_loss(y, y_) \n",
    "        #   = - 1/n * \\sum_{i=1}^n (y_i - y_hat_i)^2\n",
    "        \"\"\"\n",
    "        self.squared_error = np.square(y - y_)\n",
    "        return np.mean(self.squared_error)\n",
    "\n",
    "    def _optimize(self, X, y):\n",
    "        \"\"\"Optimize by stochastic gradient descent.\"\"\"\n",
    "        m = X.shape[0]\n",
    "\n",
    "        y_ = self._model(X) \n",
    "        dw = 1 / m * np.matmul(X.T, y_ - y)\n",
    "        db = np.mean(y_ - y)\n",
    "\n",
    "        for (param, grad) in zip([self.w, self.b], [dw, db]):\n",
    "            param[:] = param - self.lr * grad\n",
    "\n",
    "    def _fetch_batch(self):\n",
    "        \"\"\"Fetch batch dataset.\"\"\"\n",
    "        idx = list(range(self.n_examples))\n",
    "        for i in range(0, self.n_examples, self.batch_size):\n",
    "            idx_batch = idx[i:min(i + self.batch_size, self.n_examples)]\n",
    "            yield (self.X_train.take(idx_batch, axis=0), \n",
    "                   self.y_train.take(idx_batch, axis=0))\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit model.\"\"\"\n",
    "        self._create_weights()\n",
    "\n",
    "        for epoch in range(1, self.n_epochs + 1):\n",
    "            total_loss = 0\n",
    "            for X_train_b, y_train_b in self._fetch_batch():\n",
    "                y_train_b = y_train_b.reshape((y_train_b.shape[0], -1))\n",
    "                self._optimize(X_train_b, y_train_b)\n",
    "                batch_loss = self._loss(y_train_b, self._model(X_train_b))\n",
    "                total_loss += batch_loss * X_train_b.shape[0]\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print('epoch {0}: training loss {1}'\n",
    "                      .format(epoch, total_loss / self.n_examples))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_coeff(self):\n",
    "        return self.b, self.w.reshape((-1,))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self._model(X).reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression as LinearRegressionSklearn\n",
    "\n",
    "# https://github.com/bowen0701/machine-learning/blob/master/metrics.py\n",
    "!cp \"/notebooks/machine-learning/metrics.py\" .\n",
    "from metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read California housing data.\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.32520000e+00,  4.10000000e+01,  6.98412698e+00,\n",
       "         1.02380952e+00,  3.22000000e+02,  2.55555556e+00,\n",
       "         3.78800000e+01, -1.22230000e+02],\n",
       "       [ 8.30140000e+00,  2.10000000e+01,  6.23813708e+00,\n",
       "         9.71880492e-01,  2.40100000e+03,  2.10984183e+00,\n",
       "         3.78600000e+01, -1.22220000e+02],\n",
       "       [ 7.25740000e+00,  5.20000000e+01,  8.28813559e+00,\n",
       "         1.07344633e+00,  4.96000000e+02,  2.80225989e+00,\n",
       "         3.78500000e+01, -1.22240000e+02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test datasets.\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=71, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 8) (15480,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw.shape, y_train.shape)\n",
    "print(X_test_raw.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering for standardizing features by min-max scaler.\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "X_train = min_max_scaler.fit_transform(X_train_raw)\n",
    "X_test = min_max_scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert arrays to float32.\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    np.float32(X_train), np.float32(X_test), np.float32(y_train), np.float32(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype, y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Linear Regression in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our Linear Regression.\n",
    "linreg = LinearRegression(batch_size=64, lr=0.1, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datasets and build graph.\n",
    "linreg.get_data(X_train, y_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100: training loss 0.5293563370658436\n",
      "epoch 200: training loss 0.5275734594735062\n",
      "epoch 300: training loss 0.5265158852838248\n",
      "epoch 400: training loss 0.5256572463949015\n",
      "epoch 500: training loss 0.5249111460382239\n",
      "epoch 600: training loss 0.5242498661370676\n",
      "epoch 700: training loss 0.5236576673849905\n",
      "epoch 800: training loss 0.5231234686938776\n",
      "epoch 900: training loss 0.5226389617068218\n",
      "epoch 1000: training loss 0.5221977221543459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x7fe51afba0f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.8694367]]),\n",
       " array([ 5.73372961,  0.50739872, -3.33683057,  8.48590097, -0.04395446,\n",
       "        -3.99943332, -4.18663508, -4.56104079]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get coefficient.\n",
    "linreg.get_coeff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.56133286, 1.39834383, 2.14952592, 3.73451918, 2.9295695 ,\n",
       "       1.94008646, 2.21184873, 0.97634259, 0.9146045 , 1.83039715])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted response for training data.\n",
    "y_train_ = linreg.predict(X_train)\n",
    "y_train_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5284810584720984"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction squared error for training data.\n",
    "mean_squared_error(y_train, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.66620143, 2.83664128, 2.27498959, 2.75466997, 2.9009546 ,\n",
       "       1.65278449, 2.11967699, 2.69806821, 2.03915454, 1.5909759 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted response for test data.\n",
    "y_test_ = linreg.predict(X_test)\n",
    "y_test_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5492088858054294"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction accuracy for test data.\n",
    "mean_squared_error(y_test, y_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Implementation of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionTorch(nn.Module):\n",
    "    \"\"\"PyTorch implementation of Linear Regression.\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=64, lr=0.01, n_epochs=1000):\n",
    "        super(LinearRegressionTorch, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "    def get_data(self, X_train, y_train, shuffle=True):\n",
    "        \"\"\"Get dataset and information.\"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        # Get the numbers of examples and inputs.\n",
    "        self.n_examples, self.n_inputs = self.X_train.shape\n",
    "\n",
    "        if shuffle:\n",
    "            idx = list(range(self.n_examples))\n",
    "            random.shuffle(idx)\n",
    "            self.X_train = self.X_train[idx]\n",
    "            self.y_train = self.y_train[idx]\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Linear regression model.\"\"\"\n",
    "        self.net = nn.Linear(self.n_inputs, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_red = self.net(x)\n",
    "        return y_red\n",
    "\n",
    "    def _create_loss(self):\n",
    "        \"\"\"Squared error loss.\n",
    "\n",
    "        # squared_error_loss(y, y_) \n",
    "        #   = - 1/n * \\sum_{i=1}^n (y_i - y__i)^2\n",
    "        \"\"\"\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def _create_optimizer(self):\n",
    "        \"\"\"Optimize by stochastic gradient descent.\"\"\"\n",
    "        self.optimizer = optim.SGD(self.net.parameters(), lr=self.lr)\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Build computational graph.\"\"\"\n",
    "        self._create_model()\n",
    "        self._create_loss()\n",
    "        self._create_optimizer()\n",
    "\n",
    "    def _fetch_batch(self):\n",
    "        \"\"\"Fetch batch dataset.\"\"\"\n",
    "        idx = list(range(self.n_examples))\n",
    "        for i in range(0, self.n_examples, self.batch_size):\n",
    "            idx_batch = idx[i:min(i + self.batch_size, self.n_examples)]\n",
    "            yield (self.X_train.take(idx_batch, axis=0), \n",
    "                   self.y_train.take(idx_batch, axis=0))\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit model.\"\"\"\n",
    "        for epoch in range(1, self.n_epochs + 1):\n",
    "            total_loss = 0\n",
    "            for X_train_b, y_train_b in self._fetch_batch():\n",
    "                # Convert to Tensor from NumPy array and reshape ys.\n",
    "                X_train_b, y_train_b = (\n",
    "                    torch.from_numpy(X_train_b), \n",
    "                    torch.from_numpy(y_train_b).view(-1, 1))\n",
    "\n",
    "                y_pred_b = self.net(X_train_b)\n",
    "                batch_loss = self.criterion(y_pred_b, y_train_b)\n",
    "                total_loss += batch_loss * X_train_b.shape[0]\n",
    "\n",
    "                # Zero grads, performs backward pass, and update weights.\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch {0}: training loss: {1}'\n",
    "                      .format(epoch, total_loss / self.n_examples))\n",
    "\n",
    "    def get_coeff(self):\n",
    "        \"\"\"Get model coefficients.\"\"\"\n",
    "        # Detach var which require grad.\n",
    "        return self.net.bias.detach().numpy(), self.net.weight.detach().numpy()\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict for new data.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            X_ = torch.from_numpy(X)\n",
    "            return self.net(X_).numpy().reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Linear Regression in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our Linear Regression.\n",
    "linreg_torch = LinearRegressionTorch(batch_size=64, lr=0.1, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_torch.get_data(X_train, y_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_torch.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=1, bias=True)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_torch.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: training loss: 0.5316377878189087\n",
      "Epoch 200: training loss: 0.5297052264213562\n",
      "Epoch 300: training loss: 0.5282834768295288\n",
      "Epoch 400: training loss: 0.5271416306495667\n",
      "Epoch 500: training loss: 0.5262001156806946\n",
      "Epoch 600: training loss: 0.5254138112068176\n",
      "Epoch 700: training loss: 0.5247516632080078\n",
      "Epoch 800: training loss: 0.5241917967796326\n",
      "Epoch 900: training loss: 0.5237173438072205\n",
      "Epoch 1000: training loss: 0.5233145952224731\n"
     ]
    }
   ],
   "source": [
    "linreg_torch.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.792725], dtype=float32),\n",
       " array([[ 5.948561  ,  0.5364436 , -7.015867  , 12.827489  , -0.02664179,\n",
       "         -4.711181  , -4.0869713 , -4.482226  ]], dtype=float32))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get coefficient.\n",
    "linreg_torch.get_coeff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5655985 , 1.4451199 , 2.1933067 , 3.7847376 , 2.9887996 ,\n",
       "       1.9764644 , 2.2598333 , 1.0112829 , 0.98555326, 1.8750244 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted response for training data.\n",
    "y_train_ = linreg_torch.predict(X_train)\n",
    "y_train_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5223769"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction squared error for training data.\n",
    "mean_squared_error(y_train, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7113876, 2.839499 , 2.3097496, 2.7859013, 2.908202 , 1.6964045,\n",
       "       2.1401734, 2.7307498, 2.0823755, 1.633853 ], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted response for test data.\n",
    "y_test_ = linreg_torch.predict(X_test)\n",
    "y_test_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54311526"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction accuracy for test data.\n",
    "mean_squared_error(y_test, y_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Implementation of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_tf_graph(seed=71):\n",
    "    \"\"\"Reset default TensorFlow graph.\"\"\"\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "class LinearRegressionTF(object):\n",
    "    \"\"\"A TensorFlow implementation of Linear Regression.\"\"\"\n",
    "    def __init__(self, batch_size=64, learning_rate=0.01, n_epochs=1000):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_data(self, X_train, y_train, shuffle=True):\n",
    "        \"\"\"Get dataset and information.s\"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        # Get the numbers of examples and inputs.\n",
    "        self.n_examples, self.n_inputs = self.X_train.shape\n",
    "\n",
    "        idx = list(range(self.n_examples))\n",
    "        if shuffle:\n",
    "            random.shuffle(idx)\n",
    "        self.X_train = self.X_train[idx]\n",
    "        self.y_train = self.y_train[idx]\n",
    "\n",
    "    def _create_placeholders(self):\n",
    "        \"\"\"Create placeholder for features and response.\"\"\"\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, self.n_inputs), name='X')\n",
    "        self.y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "    def _create_weights(self):\n",
    "        \"\"\"Create and initialize model weights and bias.\"\"\"\n",
    "        self.w = tf.get_variable(shape=[self.n_inputs, 1],\n",
    "                                 initializer=tf.random_normal_initializer(),\n",
    "                                 name='weights')\n",
    "        self.b = tf.get_variable(shape=[1],\n",
    "                                 initializer=tf.zeros_initializer(),\n",
    "                                 name='bias')\n",
    "\n",
    "    def _model(self, X):\n",
    "        \"\"\"Linear regression model.\"\"\"\n",
    "        return tf.matmul(X, self.w) + self.b\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Create linear model.\"\"\"\n",
    "        self.y_ = self._model(self.X)\n",
    "\n",
    "    def _create_loss(self):\n",
    "        # Create mean squared error loss.\n",
    "        self.loss = tf.reduce_mean(tf.square(self.y_ - self.y), name='loss')\n",
    "\n",
    "    def _create_optimizer(self):\n",
    "        # Create gradient descent optimization.\n",
    "        self.optimizer = (\n",
    "            tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate)\n",
    "            .minimize(self.loss))\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Build computational graph.\"\"\"\n",
    "        self._create_placeholders()\n",
    "        self._create_weights()\n",
    "        self._create_model()\n",
    "        self._create_loss()\n",
    "        self._create_optimizer()\n",
    "\n",
    "    def _fetch_batch(self):\n",
    "        \"\"\"Fetch batch dataset.\"\"\"\n",
    "        idx = list(range(self.n_examples))\n",
    "        for i in range(0, self.n_examples, self.batch_size):\n",
    "            idx_batch = idx[i:min(i + self.batch_size, self.n_examples)]\n",
    "            yield (self.X_train[idx_batch, :], self.y_train[idx_batch].reshape(-1, 1))\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit model.\"\"\"\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch in range(1, self.n_epochs + 1):\n",
    "                total_loss = 0\n",
    "                for X_train_b, y_train_b in self._fetch_batch():\n",
    "                    feed_dict = {self.X: X_train_b, self.y: y_train_b}\n",
    "                    _, batch_loss = sess.run([self.optimizer, self.loss],\n",
    "                                             feed_dict=feed_dict)\n",
    "                    total_loss += batch_loss * X_train_b.shape[0]\n",
    "\n",
    "                if epoch % 100 == 0:\n",
    "                    print('Epoch {0}: training loss: {1}'\n",
    "                          .format(epoch, total_loss / self.n_examples))\n",
    "\n",
    "            # Save model.\n",
    "            saver.save(sess, 'checkpoints/linreg')\n",
    "\n",
    "    def get_coeff(self):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # Load model.\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, 'checkpoints/linreg')\n",
    "            return self.b.eval(), self.w.eval().reshape((-1,))\n",
    "\n",
    "    def predict(self, X):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # Load model.\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, 'checkpoints/linreg')\n",
    "            return self._model(X).eval().reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Logistic Regression in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_tf_graph()\n",
    "linreg_tf = LinearRegressionTF(batch_size=64, learning_rate=0.1, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_tf.get_data(X_train, y_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_tf.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: training loss: 0.5313578103709898\n",
      "Epoch 200: training loss: 0.5296086279612795\n",
      "Epoch 300: training loss: 0.528270764529551\n",
      "Epoch 400: training loss: 0.5271825757599616\n",
      "Epoch 500: training loss: 0.5262796482528519\n",
      "Epoch 600: training loss: 0.5255223750760081\n",
      "Epoch 700: training loss: 0.5248835207263937\n",
      "Epoch 800: training loss: 0.5243429550212791\n",
      "Epoch 900: training loss: 0.5238846719881053\n",
      "Epoch 1000: training loss: 0.5234957597206421\n"
     ]
    }
   ],
   "source": [
    "linreg_tf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/linreg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3.806974], dtype=float32),\n",
       " array([ 5.955759  ,  0.5073116 , -7.0784802 , 12.865215  , -0.03720079,\n",
       "        -4.6820827 , -4.0801024 , -4.484127  ], dtype=float32))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_tf.get_coeff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/linreg\n",
      "[1.5626693 1.4334488 2.1840513 3.7922604 2.9843884 1.9680834 2.2502956\n",
      " 1.0205975 0.9930382 1.8691006]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5223551"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted probabilities for training data.\n",
    "y_train_ = linreg_tf.predict((tf.cast(X_train, dtype=tf.float32)))\n",
    "print(y_train_[:10])\n",
    "\n",
    "# Prediction mean squared error for training data.\n",
    "mean_squared_error(y_train, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/linreg\n",
      "[1.7186515 2.8415976 2.2978573 2.7967334 2.903102  1.6998186 2.1301503\n",
      " 2.728647  2.0734162 1.6343772]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.54285735"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted probabilities for test data.\n",
    "y_test_ = linreg_tf.predict((tf.cast(X_test, dtype=tf.float32)))\n",
    "print(y_test_[:10])\n",
    "\n",
    "# Prediction mean squared error for training data.\n",
    "mean_squared_error(y_test, y_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark with Sklearn's Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit sklearn's Logistic Regression.\n",
    "linreg_sk = LinearRegressionSklearn()\n",
    "\n",
    "linreg_sk.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.6417923,\n",
       " array([  6.348496  ,   0.5144263 , -14.455919  ,  21.595474  ,\n",
       "         -0.04895439,  -4.965696  ,  -3.9162228 ,  -4.3132935 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get coefficients.\n",
    "linreg_sk.intercept_, linreg_sk.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5379176, 1.472091 , 2.2133121, 3.8295603, 3.0244732, 1.9933348,\n",
       "       2.263915 , 1.0535035, 1.0954115, 1.9086264], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted labels for training data.\n",
    "y_train_ = linreg_sk.predict(X_train)\n",
    "y_train_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51953274"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction squared error for training data.\n",
    "mean_squared_error(y_train, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.75787538, 2.8031482 , 2.30476246, 2.80146927, 2.87024621,\n",
       "       1.75832087, 2.11390826, 2.71989601, 2.10377988, 1.68258784])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted labels for test data.\n",
    "y_test_ = linreg_sk.predict(X_test)\n",
    "y_test_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5393498488643094"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Prediction accuracy for test data.\n",
    "mean_squared_error(y_test, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
