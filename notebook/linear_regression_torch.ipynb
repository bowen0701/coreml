{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy8bOp83Z4SN"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 71\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "kSuqDYFQjHAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a Linear Regression"
      ],
      "metadata": {
        "id": "Jn5_YpWR8CR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(nn.Module):\n",
        "    \"\"\"PyTorch implementation of Linear Regression.\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim: int) -> None:\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        # Linear regression.\n",
        "        self.fc1 = nn.Linear(self.input_dim, 1)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "CMU9vXrPavbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## California Housing Dataset"
      ],
      "metadata": {
        "id": "ssZrPq3KYIzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ],
      "metadata": {
        "id": "Ajecb5v2YgYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read housing data.\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "print(X[:3])\n",
        "print(y[:3])"
      ],
      "metadata": {
        "id": "rNlgoCs_YiPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a1131b-7ee5-44d7-b3e6-2112bfd7b533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8.32520000e+00  4.10000000e+01  6.98412698e+00  1.02380952e+00\n",
            "   3.22000000e+02  2.55555556e+00  3.78800000e+01 -1.22230000e+02]\n",
            " [ 8.30140000e+00  2.10000000e+01  6.23813708e+00  9.71880492e-01\n",
            "   2.40100000e+03  2.10984183e+00  3.78600000e+01 -1.22220000e+02]\n",
            " [ 7.25740000e+00  5.20000000e+01  8.28813559e+00  1.07344633e+00\n",
            "   4.96000000e+02  2.80225989e+00  3.78500000e+01 -1.22240000e+02]]\n",
            "[4.526 3.585 3.521]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(housing.feature_names)"
      ],
      "metadata": {
        "id": "ezU4gW5-YqB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e32973e-abcc-44fe-fd1f-f914f2ea0f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Tuple\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "batch_size = 32\n",
        "is_shuffle = True\n",
        "\n",
        "\n",
        "def housing_data_reader():\n",
        "    housing = fetch_california_housing()\n",
        "    examples, labels = housing.data, housing.target\n",
        "    return (examples, labels)\n",
        "\n",
        "# Build housing dataset.\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, \n",
        "        data_reader: Any = None, \n",
        "        transform: Any = None, \n",
        "        target_transform: Any = None\n",
        "    ) -> None:\n",
        "        self.examples, self.labels = data_reader()\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[Tensor, float]:\n",
        "        example = self.examples[idx, :]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            example = self.transform(example)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(self)\n",
        "        return example, label"
      ],
      "metadata": {
        "id": "DNT_BYfJY2cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(\n",
        "    data_reader=housing_data_reader,\n",
        ")"
      ],
      "metadata": {
        "id": "8yZUvuNncDiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and test datasets.\n",
        "def split_dataset(dataset: Dataset, train_dataset_ratio: float = 0.8) -> Tuple[Dataset, Dataset]:\n",
        "    num_examples = len(dataset)\n",
        "    num_train_examples = int(train_dataset_ratio * num_examples)\n",
        "    num_test_examples = num_examples - num_train_examples\n",
        "    train_dataset, test_dataset = random_split(dataset, [num_train_examples, num_test_examples])\n",
        "    return train_dataset, test_dataset"
      ],
      "metadata": {
        "id": "OCdj-0-eob0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = split_dataset(dataset, train_dataset_ratio=0.8) "
      ],
      "metadata": {
        "id": "WZxPcfwP5jj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset), len(test_dataset))"
      ],
      "metadata": {
        "id": "jQvCz4EQjNbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "decd6756-000b-45a0-e484-261b2d7db5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16512 4128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=is_shuffle)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=is_shuffle)"
      ],
      "metadata": {
        "id": "6jx92pcuUb1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples, train_labels = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "peshC0Ifgl9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples[:3]"
      ],
      "metadata": {
        "id": "MECPunOcD4jI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1739865d-fa3a-430f-b49b-136bf2923e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.2417e+00,  1.8000e+01,  5.1502e+00,  1.0120e+00,  1.1660e+03,\n",
              "          3.5015e+00,  3.2770e+01, -1.1552e+02],\n",
              "        [ 1.9028e+00,  3.6000e+01,  3.2949e+00,  9.7863e-01,  1.7110e+03,\n",
              "          3.6560e+00,  3.3960e+01, -1.1822e+02],\n",
              "        [ 5.5413e+00,  2.6000e+01,  6.5684e+00,  1.0711e+00,  1.0620e+03,\n",
              "          2.7947e+00,  3.2810e+01, -1.1721e+02]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1 + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYKFeKNz6P9I",
        "outputId": "1a4896c7-dee3-4caa-8e90-a1f2b7109740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class "
      ],
      "metadata": {
        "id": "p2U8hM71GgDN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}